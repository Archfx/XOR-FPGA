{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR Prediction Neural Network\n",
    "#### A simple neural network which will learn the XOR logic gate.\n",
    "\n",
    "I will provide you with any links necessary so that you can read about the different aspects of this NN(Neural Network)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Info\n",
    "\n",
    "#### All information regarding the neural network:\n",
    "\n",
    "- Input Layer Units = 2 \n",
    "- Hidden Layer Units = 3\n",
    "- Output Layer Units = 1\n",
    "\n",
    "- No. of hidden layers = 1\n",
    "- Learning Algorithm = Backpropagation\n",
    "\n",
    "\n",
    "\n",
    "Feel free to mess around with it and try out different things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # For matrix math\n",
    "import matplotlib.pyplot as plt # For plotting\n",
    "\n",
    "import sys # For printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Implementation\n",
    "Initially, I was going to approach this in an Object Oriented manner but I think that it would be much easier to read and implement, functionally. So, let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data\n",
    "\n",
    "The XOR logic gate returns true when the number of inputs given is odd and false when they're even. Here is the simple training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training data.\n",
    "X = np.array([\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "    [0, 0]\n",
    "])\n",
    "\n",
    "# The labels for the training data.\n",
    "y = np.array([\n",
    "    [1],\n",
    "    [1],\n",
    "    [0],\n",
    "    [0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Parameters\n",
    "These are just additional parameters which are required by the weights for their dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_i_units = 2 # Number of Input units\n",
    "num_h_units = 3 # Number of Hidden units\n",
    "num_o_units = 1 # Number of Output units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Parameters\n",
    "These are the parameters required directly by the NN. Comments should describe the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The learning rate for Gradient Descent.\n",
    "learning_rate = 0.01\n",
    "\n",
    "# The parameter to help with overfitting.\n",
    "reg_param = 0\n",
    "\n",
    "# Maximum iterations for Gradient Descent.\n",
    "max_iter = 50000\n",
    "\n",
    "# Number of training examples\n",
    "m = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights and Biases\n",
    "These are the numbers the NN needs to learn to make accurate predictions.\n",
    "\n",
    "For the connections being made from the input layer to the hidden layer, the weights and biases are arranged in the following order: **each row contains the weights for each hidden unit**. Then, the shape of these set of weights is: *(number of hidden units X number of input units)* and the shape of the biases for this connection will be: *(number of hidden units X 1)*.\n",
    "\n",
    "So, the overall shape of the weights and biases are:\n",
    "\n",
    "**Weights1(Connection from input to hidden layers)**: num_h_units X num_i_units\n",
    "**Biases1(Connection from input to hidden layers)**: num_h_units X 1\n",
    "\n",
    "**Weights2(Connection from hidden to output layers)**: num_o_units X num_h_units\n",
    "**Biases2(Connection from hidden to output layers)**: num_o_units X 1\n",
    "\n",
    "### Generating the Weights\n",
    "\n",
    "The weights here are going to be generated using a [Normal Distribution(Gaussian Distribution)](http://mathworld.wolfram.com/NormalDistribution.html). They will also be seeded so that the outcome always comes out the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "W1 = np.random.normal(0, 1, (num_h_units, num_i_units)) # 2x2\n",
    "W2 = np.random.normal(0, 1, (num_o_units, num_h_units)) # 1x2\n",
    "\n",
    "B1 = np.random.random((num_h_units, 1)) # 2x1\n",
    "B2 = np.random.random((num_o_units, 1)) # 1x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.62434536, -0.61175641],\n",
       "       [-0.52817175, -1.07296862],\n",
       "       [ 0.86540763, -2.3015387 ]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.74481176, -0.7612069 ,  0.3190391 ]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02738759],\n",
       "       [0.67046751],\n",
       "       [0.4173048 ]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55868983]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B2"
   ]
  },
  {
   "attachments": {
    "sigmoid-curve.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Function\n",
    "[This](http://mathworld.wolfram.com/SigmoidFunction.html) function maps any input to a value between 0 and 1.\n",
    "\n",
    "![sigmoid-curve.png](attachment:sigmoid-curve.png)\n",
    "\n",
    "In my implementation, I have added a boolean which if set to true, will return [Sigmoid Prime(the derivative of the sigmoid function)](http://www.ai.mit.edu/courses/6.892/lecture8-html/sld015.htm) of the input value. This will be used in backpropagation later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z, derv=False):\n",
    "    if derv: return z * (1 - z)\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation\n",
    "[This](https://en.wikipedia.org/wiki/Feedforward_neural_network) is how predictions are made. Propagating the input through the NN to get the output.\n",
    "\n",
    "In my implementation, the forward function only accepts a feature vector as row vector which is then converted to a column vector. Also, the predict boolean, if set to true, only returns the output. Otherwise, it returns a tuple of the outputs of all the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, predict=False):\n",
    "    a1 = x.reshape(x.shape[0], 1) # Getting the training example as a column vector.\n",
    "\n",
    "    z2 = W1.dot(a1) + B1 # 2x2 * 2x1 + 2x1 = 2x1\n",
    "    a2 = sigmoid(z2) # 2x1\n",
    "\n",
    "    z3 = W2.dot(a2) + B2 # 1x2 * 2x1 + 1x1 = 1x1\n",
    "    a3 = sigmoid(z3)\n",
    "\n",
    "    if predict: return a3\n",
    "    return (a1, a2, a3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients for the Weights and Biases\n",
    "These variables will contain the gradients for the weights and biases which will be used by gradient descent to update the weights and biases.\n",
    "\n",
    "Also, creating the vector which will be storing the cost values for each gradient descent iteration to help visualize the cost as the weights and biases are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW1 = 0 # Gradient for W1\n",
    "dW2 = 0 # Gradient for W2\n",
    "\n",
    "dB1 = 0 # Gradient for B1\n",
    "dB2 = 0 # Gradient for B2\n",
    "\n",
    "cost = np.zeros((max_iter, 1)) # Column vector to record the cost of the NN after each Gradient Descent iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "This is the training function which contains the meat of NN. This contains forward propagation and [Backpropagation](http://neuralnetworksanddeeplearning.com/chap2.html).\n",
    "\n",
    "### Backpropagation\n",
    "The process of propagating the error in the output layer, backwards through the NN to calculate the error in each layer. Intuition: It's like forward propagation, but backwards.\n",
    "\n",
    "Steps(for this NN):\n",
    "1. Calculate the error in the output layer(dz2).\n",
    "2. Calculate the error in the weights connecting the hidden layer to the output layer using dz2 (dW2).\n",
    "3. Calculate the error in the hidden layer(dz1).\n",
    "4. Calculate the error in the weights connecting the input layer to the hidden layer using dz1 (dW1).\n",
    "5. The errors in the biases are just the errors in the respective layers.\n",
    "\n",
    "Afterwards, the gradients(errors) of the weights and biases are used to update the corresponding weights and biases by multiplying them with the negative of the learning rate and scaling it by divinding it by the number of training examples.\n",
    "\n",
    "While iterating over all the training examples, the cost is also being calculated simultaneously for each example. Then, a regurlization parameter is added, although for such a small dataset, regularization is unnecessary since to perform well, the NN will have to over fit to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(_W1, _W2, _B1, _B2): # The arguments are to bypass UnboundLocalError error\n",
    "    for i in range(max_iter):\n",
    "        c = 0\n",
    "        \n",
    "        dW1 = 0\n",
    "        dW2 = 0\n",
    "\n",
    "        dB1 = 0\n",
    "        dB2 = 0\n",
    "        \n",
    "        for j in range(m):\n",
    "            sys.stdout.write(\"\\rIteration: {} and {}\".format(i + 1, j + 1))\n",
    "\n",
    "            # Forward Prop.\n",
    "            a0 = X[j].reshape(X[j].shape[0], 1) # 2x1\n",
    "\n",
    "            z1 = _W1.dot(a0) + _B1 # 2x2 * 2x1 + 2x1 = 2x1\n",
    "            a1 = sigmoid(z1) # 2x1\n",
    "\n",
    "            z2 = _W2.dot(a1) + _B2 # 1x2 * 2x1 + 1x1 = 1x1\n",
    "            a2 = sigmoid(z2) # 1x1\n",
    "\n",
    "            # Back prop.\n",
    "            dz2 = a2 - y[j] # 1x1\n",
    "            dW2 += dz2 * a1.T # 1x1 .* 1x2 = 1x2\n",
    "\n",
    "            dz1 = np.multiply((_W2.T * dz2), sigmoid(a1, derv=True)) # (2x1 * 1x1) .* 2x1 = 2x1\n",
    "            dW1 += dz1.dot(a0.T) # 2x1 * 1x2 = 2x2\n",
    "\n",
    "            dB1 += dz1 # 2x1\n",
    "            dB2 += dz2 # 1x1\n",
    "\n",
    "            c = c + (-(y[j] * np.log(a2)) - ((1 - y[j]) * np.log(1 - a2)))\n",
    "            sys.stdout.flush() # Updating the text.\n",
    "        \n",
    "        _W1 = _W1 - learning_rate * (dW1 / m) + ( (reg_param / m) * _W1)\n",
    "        _W2 = _W2 - learning_rate * (dW2 / m) + ( (reg_param / m) * _W2)\n",
    "\n",
    "        _B1 = _B1 - learning_rate * (dB1 / m)\n",
    "        _B2 = _B2 - learning_rate * (dB2 / m)\n",
    "        cost[i] = (c / m) + ( \n",
    "            (reg_param / (2 * m)) * \n",
    "            (\n",
    "                np.sum(np.power(_W1, 2)) + \n",
    "                np.sum(np.power(_W2, 2))\n",
    "            )\n",
    "        )\n",
    "    return (_W1, _W2, _B1, _B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running\n",
    "Now, let's try out the NN. Here, I have called the train() function. You can make any changes you like and then run all the kernels again. I have also plotted the cost function to visual how the NN performed.\n",
    "\n",
    "The console printing might be off.\n",
    "\n",
    "The weights and biases are then shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 50000 and 4"
     ]
    }
   ],
   "source": [
    "W1, W2, B1, B2 = train(W1, W2, B1, B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.74185753, -6.13103778],\n",
       "       [-3.50823244, -4.63758001],\n",
       "       [ 5.51520192, -3.77964294]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.5194821 , -4.41987076, -6.63780666]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.32319703],\n",
       "       [ 0.72576663],\n",
       "       [ 1.32843545]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.38932348]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "Now, let's plot a simple plot showing the cost function with respect to the number of iterations of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assigning the axes to the different elements.\n",
    "plt.plot(range(max_iter), cost)\n",
    "\n",
    "# Labelling the x axis as the iterations axis.\n",
    "plt.xlabel(\"Iterations\")\n",
    "\n",
    "# Labelling the y axis as the cost axis.\n",
    "plt.ylabel(\"Cost\")\n",
    "\n",
    "# Showing the plot.\n",
    "plt.show()\n",
    "plt.savefig('1sr.jpg', bbox_inches='tight', pad_inches=0.0, dpi=200,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01527777]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(np.array([0, 0]),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch implementation\n",
    "\n",
    "Without using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # For matrix math\n",
    "import matplotlib.pyplot as plt # For plotting\n",
    "\n",
    "import sys # For printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [1, 0], [1, 1], [0, 0]]\n"
     ]
    }
   ],
   "source": [
    "X = [[0, 1],[1, 0],[1, 1],[0, 0]]\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =[[1],[1],[0],[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_i_units = 2 # Number of Input units\n",
    "num_h_units = 3 # Number of Hidden units\n",
    "num_o_units = 1 # Number of Output units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The learning rate for Gradient Descent.\n",
    "learning_rate = 0.01\n",
    "\n",
    "# The parameter to help with overfitting.\n",
    "reg_param = 0\n",
    "\n",
    "# Maximum iterations for Gradient Descent.\n",
    "max_iter = 50000\n",
    "\n",
    "# Number of training examples\n",
    "m = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = [[ 47, -61],[-35, -46],[ 55, -37]]\n",
    "W2 = [ 75 , -44, -66]\n",
    "\n",
    "B1 = [-23,7,13]\n",
    "B2 = [33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuned parameters\n",
    "# W1 = [[ 4.74185753, -6.13103778],[-3.50823244, -4.63758001],[ 5.51520192, -3.77964294]]\n",
    "# W2 = [ 7.5194821 , -4.41987076, -6.63780666]\n",
    "\n",
    "# B1 = [-2.32319703,0.72576663,1.32843545]\n",
    "# B2 = [3.38932348]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z, derv=False):\n",
    "    if derv: return z * (1 - z)\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, predict=False):\n",
    "    #a1 = x.reshape(x.shape[0], 1) # Getting the training example as a column vector.\n",
    "    z2=[0,0,0]\n",
    "    for i in range (len(x)):\n",
    "        z2[0]+=W1[0][i]*x[i]\n",
    "        z2[1]+=W1[1][i]*x[i]\n",
    "        z2[2]+=W1[2][i]*x[i]\n",
    "    z2[0]+=B1[0]\n",
    "    z2[1]+=B1[1]\n",
    "    z2[2]+=B1[2]\n",
    "    \n",
    "    print (z2)\n",
    "    \n",
    "    z2[0]=z2[0]/10\n",
    "    z2[1]=z2[1]/10\n",
    "    z2[2]=z2[2]/10\n",
    "#     z2 = W1.dot(a1) + B1 # 2x2 * 2x1 + 2x1 = 2x1\n",
    "    a2 = sigmoid(np.array(z2))\n",
    "    a2.tolist()\n",
    "    \n",
    "    a2[0]=int(a2[0]*100)\n",
    "    a2[1]=int(a2[1]*100)\n",
    "    a2[2]=int(a2[2]*100)\n",
    "    \n",
    "    print (a2)\n",
    "    z3=0\n",
    "    for i in range (len(a2)):\n",
    "        z3+=W2[i]*a2[i]/100\n",
    "    z3+=B2[0]\n",
    "    print (z3)\n",
    "    a3 = sigmoid(np.array(z3/10))\n",
    "\n",
    "    if predict: return int(a3*100)\n",
    "    return (a1, a2, a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-23, 7, 13]\n",
      "[ 9. 66. 78.]\n",
      "-40.769999999999996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward([0,0],True)\n",
    "# 00-0.0011639148470746173\n",
    "# 11-0.01278397172659985\n",
    "# 01-0.036059012680189254\n",
    "# 10-0.32815600427794245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid_m(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8'sd 0 : out<= 8'sd 50 ;\n",
      "8'sd 1 : out<= 8'sd 52 ;\n",
      "8'sd 2 : out<= 8'sd 54 ;\n",
      "8'sd 3 : out<= 8'sd 57 ;\n",
      "8'sd 4 : out<= 8'sd 59 ;\n",
      "8'sd 5 : out<= 8'sd 62 ;\n",
      "8'sd 6 : out<= 8'sd 64 ;\n",
      "8'sd 7 : out<= 8'sd 66 ;\n",
      "8'sd 8 : out<= 8'sd 68 ;\n",
      "8'sd 9 : out<= 8'sd 71 ;\n",
      "8'sd 10 : out<= 8'sd 73 ;\n",
      "8'sd 11 : out<= 8'sd 75 ;\n",
      "8'sd 12 : out<= 8'sd 76 ;\n",
      "8'sd 13 : out<= 8'sd 78 ;\n",
      "8'sd 14 : out<= 8'sd 80 ;\n",
      "8'sd 15 : out<= 8'sd 81 ;\n",
      "8'sd 16 : out<= 8'sd 83 ;\n",
      "8'sd 17 : out<= 8'sd 84 ;\n",
      "8'sd 18 : out<= 8'sd 85 ;\n",
      "8'sd 19 : out<= 8'sd 86 ;\n",
      "8'sd 20 : out<= 8'sd 88 ;\n",
      "8'sd 21 : out<= 8'sd 89 ;\n",
      "8'sd 22 : out<= 8'sd 90 ;\n",
      "8'sd 23 : out<= 8'sd 90 ;\n",
      "8'sd 24 : out<= 8'sd 91 ;\n",
      "8'sd 25 : out<= 8'sd 92 ;\n",
      "8'sd 26 : out<= 8'sd 93 ;\n",
      "8'sd 27 : out<= 8'sd 93 ;\n",
      "8'sd 28 : out<= 8'sd 94 ;\n",
      "8'sd 29 : out<= 8'sd 94 ;\n",
      "8'sd 30 : out<= 8'sd 95 ;\n",
      "8'sd 31 : out<= 8'sd 95 ;\n",
      "8'sd 32 : out<= 8'sd 96 ;\n",
      "8'sd 33 : out<= 8'sd 96 ;\n",
      "8'sd 34 : out<= 8'sd 96 ;\n",
      "8'sd 35 : out<= 8'sd 97 ;\n",
      "8'sd 36 : out<= 8'sd 97 ;\n",
      "8'sd 37 : out<= 8'sd 97 ;\n",
      "8'sd 38 : out<= 8'sd 97 ;\n",
      "8'sd 39 : out<= 8'sd 98 ;\n",
      "8'sd 40 : out<= 8'sd 98 ;\n",
      "8'sd 41 : out<= 8'sd 98 ;\n",
      "8'sd 42 : out<= 8'sd 98 ;\n",
      "8'sd 43 : out<= 8'sd 98 ;\n",
      "8'sd 44 : out<= 8'sd 98 ;\n",
      "8'sd 45 : out<= 8'sd 98 ;\n",
      "8'sd 46 : out<= 8'sd 99 ;\n",
      "8'sd 47 : out<= 8'sd 99 ;\n",
      "8'sd 48 : out<= 8'sd 99 ;\n",
      "8'sd 49 : out<= 8'sd 99 ;\n",
      "8'sd 50 : out<= 8'sd 99 ;\n",
      "8'sd 51 : out<= 8'sd 99 ;\n",
      "8'sd 52 : out<= 8'sd 99 ;\n",
      "8'sd 53 : out<= 8'sd 99 ;\n",
      "8'sd 54 : out<= 8'sd 99 ;\n",
      "8'sd 55 : out<= 8'sd 99 ;\n",
      "8'sd 56 : out<= 8'sd 99 ;\n",
      "8'sd 57 : out<= 8'sd 99 ;\n",
      "8'sd 58 : out<= 8'sd 99 ;\n",
      "8'sd 59 : out<= 8'sd 99 ;\n",
      "8'sd 60 : out<= 8'sd 99 ;\n",
      "8'sd 61 : out<= 8'sd 99 ;\n",
      "8'sd 62 : out<= 8'sd 99 ;\n",
      "8'sd 63 : out<= 8'sd 99 ;\n",
      "8'sd 64 : out<= 8'sd 99 ;\n",
      "8'sd 65 : out<= 8'sd 99 ;\n",
      "8'sd 66 : out<= 8'sd 99 ;\n",
      "8'sd 67 : out<= 8'sd 99 ;\n",
      "8'sd 68 : out<= 8'sd 99 ;\n",
      "8'sd 69 : out<= 8'sd 99 ;\n",
      "8'sd 70 : out<= 8'sd 99 ;\n",
      "8'sd 71 : out<= 8'sd 99 ;\n",
      "8'sd 72 : out<= 8'sd 99 ;\n",
      "8'sd 73 : out<= 8'sd 99 ;\n",
      "8'sd 74 : out<= 8'sd 99 ;\n",
      "8'sd 75 : out<= 8'sd 99 ;\n",
      "8'sd 76 : out<= 8'sd 99 ;\n",
      "8'sd 77 : out<= 8'sd 99 ;\n",
      "8'sd 78 : out<= 8'sd 99 ;\n",
      "8'sd 79 : out<= 8'sd 99 ;\n",
      "8'sd 80 : out<= 8'sd 99 ;\n",
      "8'sd 81 : out<= 8'sd 99 ;\n",
      "8'sd 82 : out<= 8'sd 99 ;\n",
      "8'sd 83 : out<= 8'sd 99 ;\n",
      "8'sd 84 : out<= 8'sd 99 ;\n",
      "8'sd 85 : out<= 8'sd 99 ;\n",
      "8'sd 86 : out<= 8'sd 99 ;\n",
      "8'sd 87 : out<= 8'sd 99 ;\n",
      "8'sd 88 : out<= 8'sd 99 ;\n",
      "8'sd 89 : out<= 8'sd 99 ;\n",
      "8'sd 90 : out<= 8'sd 99 ;\n",
      "8'sd 91 : out<= 8'sd 99 ;\n",
      "8'sd 92 : out<= 8'sd 99 ;\n",
      "8'sd 93 : out<= 8'sd 99 ;\n",
      "8'sd 94 : out<= 8'sd 99 ;\n",
      "8'sd 95 : out<= 8'sd 99 ;\n",
      "8'sd 96 : out<= 8'sd 99 ;\n",
      "8'sd 97 : out<= 8'sd 99 ;\n",
      "8'sd 98 : out<= 8'sd 99 ;\n",
      "8'sd 99 : out<= 8'sd 99 ;\n",
      "8'sd 100 : out<= 8'sd 99 ;\n",
      "8'sd 101 : out<= 8'sd 99 ;\n",
      "8'sd 102 : out<= 8'sd 99 ;\n",
      "8'sd 103 : out<= 8'sd 99 ;\n",
      "8'sd 104 : out<= 8'sd 99 ;\n",
      "8'sd 105 : out<= 8'sd 99 ;\n",
      "8'sd 106 : out<= 8'sd 99 ;\n",
      "8'sd 107 : out<= 8'sd 99 ;\n",
      "8'sd 108 : out<= 8'sd 99 ;\n",
      "8'sd 109 : out<= 8'sd 99 ;\n",
      "8'sd 110 : out<= 8'sd 99 ;\n",
      "8'sd 111 : out<= 8'sd 99 ;\n",
      "8'sd 112 : out<= 8'sd 99 ;\n",
      "8'sd 113 : out<= 8'sd 99 ;\n",
      "8'sd 114 : out<= 8'sd 99 ;\n",
      "8'sd 115 : out<= 8'sd 99 ;\n",
      "8'sd 116 : out<= 8'sd 99 ;\n",
      "8'sd 117 : out<= 8'sd 99 ;\n",
      "8'sd 118 : out<= 8'sd 99 ;\n",
      "8'sd 119 : out<= 8'sd 99 ;\n",
      "8'sd 120 : out<= 8'sd 99 ;\n",
      "8'sd 121 : out<= 8'sd 99 ;\n",
      "8'sd 122 : out<= 8'sd 99 ;\n",
      "8'sd 123 : out<= 8'sd 99 ;\n",
      "8'sd 124 : out<= 8'sd 99 ;\n",
      "8'sd 125 : out<= 8'sd 99 ;\n",
      "8'sd 126 : out<= 8'sd 99 ;\n",
      "8'sd 127 : out<= 8'sd 99 ;\n"
     ]
    }
   ],
   "source": [
    "# sigmoid case statement verilog\n",
    "for i in range (0,128):\n",
    "    print (\"8'sd\", i,\": out<= 8'sd\", int(sigmoid_m(i/10)*100) ,\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8'sd 127 : out<= 8'sd 0 ;\n",
      "-8'sd 126 : out<= 8'sd 0 ;\n",
      "-8'sd 125 : out<= 8'sd 0 ;\n",
      "-8'sd 124 : out<= 8'sd 0 ;\n",
      "-8'sd 123 : out<= 8'sd 0 ;\n",
      "-8'sd 122 : out<= 8'sd 0 ;\n",
      "-8'sd 121 : out<= 8'sd 0 ;\n",
      "-8'sd 120 : out<= 8'sd 0 ;\n",
      "-8'sd 119 : out<= 8'sd 0 ;\n",
      "-8'sd 118 : out<= 8'sd 0 ;\n",
      "-8'sd 117 : out<= 8'sd 0 ;\n",
      "-8'sd 116 : out<= 8'sd 0 ;\n",
      "-8'sd 115 : out<= 8'sd 0 ;\n",
      "-8'sd 114 : out<= 8'sd 0 ;\n",
      "-8'sd 113 : out<= 8'sd 0 ;\n",
      "-8'sd 112 : out<= 8'sd 0 ;\n",
      "-8'sd 111 : out<= 8'sd 0 ;\n",
      "-8'sd 110 : out<= 8'sd 0 ;\n",
      "-8'sd 109 : out<= 8'sd 0 ;\n",
      "-8'sd 108 : out<= 8'sd 0 ;\n",
      "-8'sd 107 : out<= 8'sd 0 ;\n",
      "-8'sd 106 : out<= 8'sd 0 ;\n",
      "-8'sd 105 : out<= 8'sd 0 ;\n",
      "-8'sd 104 : out<= 8'sd 0 ;\n",
      "-8'sd 103 : out<= 8'sd 0 ;\n",
      "-8'sd 102 : out<= 8'sd 0 ;\n",
      "-8'sd 101 : out<= 8'sd 0 ;\n",
      "-8'sd 100 : out<= 8'sd 0 ;\n",
      "-8'sd 99 : out<= 8'sd 0 ;\n",
      "-8'sd 98 : out<= 8'sd 0 ;\n",
      "-8'sd 97 : out<= 8'sd 0 ;\n",
      "-8'sd 96 : out<= 8'sd 0 ;\n",
      "-8'sd 95 : out<= 8'sd 0 ;\n",
      "-8'sd 94 : out<= 8'sd 0 ;\n",
      "-8'sd 93 : out<= 8'sd 0 ;\n",
      "-8'sd 92 : out<= 8'sd 0 ;\n",
      "-8'sd 91 : out<= 8'sd 0 ;\n",
      "-8'sd 90 : out<= 8'sd 0 ;\n",
      "-8'sd 89 : out<= 8'sd 0 ;\n",
      "-8'sd 88 : out<= 8'sd 0 ;\n",
      "-8'sd 87 : out<= 8'sd 0 ;\n",
      "-8'sd 86 : out<= 8'sd 0 ;\n",
      "-8'sd 85 : out<= 8'sd 0 ;\n",
      "-8'sd 84 : out<= 8'sd 0 ;\n",
      "-8'sd 83 : out<= 8'sd 0 ;\n",
      "-8'sd 82 : out<= 8'sd 0 ;\n",
      "-8'sd 81 : out<= 8'sd 0 ;\n",
      "-8'sd 80 : out<= 8'sd 0 ;\n",
      "-8'sd 79 : out<= 8'sd 0 ;\n",
      "-8'sd 78 : out<= 8'sd 0 ;\n",
      "-8'sd 77 : out<= 8'sd 0 ;\n",
      "-8'sd 76 : out<= 8'sd 0 ;\n",
      "-8'sd 75 : out<= 8'sd 0 ;\n",
      "-8'sd 74 : out<= 8'sd 0 ;\n",
      "-8'sd 73 : out<= 8'sd 0 ;\n",
      "-8'sd 72 : out<= 8'sd 0 ;\n",
      "-8'sd 71 : out<= 8'sd 0 ;\n",
      "-8'sd 70 : out<= 8'sd 0 ;\n",
      "-8'sd 69 : out<= 8'sd 0 ;\n",
      "-8'sd 68 : out<= 8'sd 0 ;\n",
      "-8'sd 67 : out<= 8'sd 0 ;\n",
      "-8'sd 66 : out<= 8'sd 0 ;\n",
      "-8'sd 65 : out<= 8'sd 0 ;\n",
      "-8'sd 64 : out<= 8'sd 0 ;\n",
      "-8'sd 63 : out<= 8'sd 0 ;\n",
      "-8'sd 62 : out<= 8'sd 0 ;\n",
      "-8'sd 61 : out<= 8'sd 0 ;\n",
      "-8'sd 60 : out<= 8'sd 0 ;\n",
      "-8'sd 59 : out<= 8'sd 0 ;\n",
      "-8'sd 58 : out<= 8'sd 0 ;\n",
      "-8'sd 57 : out<= 8'sd 0 ;\n",
      "-8'sd 56 : out<= 8'sd 0 ;\n",
      "-8'sd 55 : out<= 8'sd 0 ;\n",
      "-8'sd 54 : out<= 8'sd 0 ;\n",
      "-8'sd 53 : out<= 8'sd 0 ;\n",
      "-8'sd 52 : out<= 8'sd 0 ;\n",
      "-8'sd 51 : out<= 8'sd 0 ;\n",
      "-8'sd 50 : out<= 8'sd 0 ;\n",
      "-8'sd 49 : out<= 8'sd 0 ;\n",
      "-8'sd 48 : out<= 8'sd 0 ;\n",
      "-8'sd 47 : out<= 8'sd 0 ;\n",
      "-8'sd 46 : out<= 8'sd 0 ;\n",
      "-8'sd 45 : out<= 8'sd 1 ;\n",
      "-8'sd 44 : out<= 8'sd 1 ;\n",
      "-8'sd 43 : out<= 8'sd 1 ;\n",
      "-8'sd 42 : out<= 8'sd 1 ;\n",
      "-8'sd 41 : out<= 8'sd 1 ;\n",
      "-8'sd 40 : out<= 8'sd 1 ;\n",
      "-8'sd 39 : out<= 8'sd 1 ;\n",
      "-8'sd 38 : out<= 8'sd 2 ;\n",
      "-8'sd 37 : out<= 8'sd 2 ;\n",
      "-8'sd 36 : out<= 8'sd 2 ;\n",
      "-8'sd 35 : out<= 8'sd 2 ;\n",
      "-8'sd 34 : out<= 8'sd 3 ;\n",
      "-8'sd 33 : out<= 8'sd 3 ;\n",
      "-8'sd 32 : out<= 8'sd 3 ;\n",
      "-8'sd 31 : out<= 8'sd 4 ;\n",
      "-8'sd 30 : out<= 8'sd 4 ;\n",
      "-8'sd 29 : out<= 8'sd 5 ;\n",
      "-8'sd 28 : out<= 8'sd 5 ;\n",
      "-8'sd 27 : out<= 8'sd 6 ;\n",
      "-8'sd 26 : out<= 8'sd 6 ;\n",
      "-8'sd 25 : out<= 8'sd 7 ;\n",
      "-8'sd 24 : out<= 8'sd 8 ;\n",
      "-8'sd 23 : out<= 8'sd 9 ;\n",
      "-8'sd 22 : out<= 8'sd 9 ;\n",
      "-8'sd 21 : out<= 8'sd 10 ;\n",
      "-8'sd 20 : out<= 8'sd 11 ;\n",
      "-8'sd 19 : out<= 8'sd 13 ;\n",
      "-8'sd 18 : out<= 8'sd 14 ;\n",
      "-8'sd 17 : out<= 8'sd 15 ;\n",
      "-8'sd 16 : out<= 8'sd 16 ;\n",
      "-8'sd 15 : out<= 8'sd 18 ;\n",
      "-8'sd 14 : out<= 8'sd 19 ;\n",
      "-8'sd 13 : out<= 8'sd 21 ;\n",
      "-8'sd 12 : out<= 8'sd 23 ;\n",
      "-8'sd 11 : out<= 8'sd 24 ;\n",
      "-8'sd 10 : out<= 8'sd 26 ;\n",
      "-8'sd 9 : out<= 8'sd 28 ;\n",
      "-8'sd 8 : out<= 8'sd 31 ;\n",
      "-8'sd 7 : out<= 8'sd 33 ;\n",
      "-8'sd 6 : out<= 8'sd 35 ;\n",
      "-8'sd 5 : out<= 8'sd 37 ;\n",
      "-8'sd 4 : out<= 8'sd 40 ;\n",
      "-8'sd 3 : out<= 8'sd 42 ;\n",
      "-8'sd 2 : out<= 8'sd 45 ;\n",
      "-8'sd 1 : out<= 8'sd 47 ;\n"
     ]
    }
   ],
   "source": [
    "for i in range (-127,0):\n",
    "    print (\"-8'sd\", i*(-1),\": out<= 8'sd\", int(sigmoid_m(i/10)*100) ,\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
